#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Web API å®æ—¶æ•°æ®æºå®Œæ•´æ€§æµ‹è¯•è„šæœ¬
é€šè¿‡è°ƒç”¨ç³»ç»ŸWeb APIæ¥å£æµ‹è¯•å„æ•°æ®æºçš„æ•°æ®è´¨é‡å’Œå®Œæ•´æ€§
"""

import requests
import json
import time
import logging
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any
import pandas as pd
import statistics
from concurrent.futures import ThreadPoolExecutor, as_completed

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('web_api_test.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class WebAPIDataSourceTester:
    """Web APIæ•°æ®æºæµ‹è¯•å™¨"""
    
    def __init__(self, base_url: str = "http://127.0.0.1:5000"):
        self.base_url = base_url.rstrip('/')
        self.session = requests.Session()
        self.session.timeout = 10
        
        # æµ‹è¯•è‚¡ç¥¨æ± 
        self.test_stocks = [
            "000001.SZ",  # å¹³å®‰é“¶è¡Œ
            "000002.SZ",  # ä¸‡ç§‘A
            "600000.SH",  # æµ¦å‘é“¶è¡Œ
            "600036.SH",  # æ‹›å•†é“¶è¡Œ
            "600519.SH",  # è´µå·èŒ…å°
            "000858.SZ",  # äº”ç²®æ¶²
            "002415.SZ",  # æµ·åº·å¨è§†
            "000166.SZ",  # ç”³ä¸‡å®æº
        ]
        
        # æ•°æ®å®Œæ•´æ€§æ£€æŸ¥è§„åˆ™
        self.data_integrity_rules = {
            'required_fields': [
                'lastPrice', 'volume', 'amount', 'high', 'low', 'open'
            ],
            'optional_fields': [
                'lastClose', 'change', 'changePercent', 'bidPrice', 'askPrice',
                'bidVol', 'askVol', 'timestamp', 'source'
            ],
            'price_range_check': True,
            'volume_check': True,
            'logical_check': True
        }
        
        self.test_results = {}
    
    def make_request(self, endpoint: str, method: str = 'GET', data: Dict = None) -> Tuple[bool, Dict]:
        """å‘é€HTTPè¯·æ±‚"""
        url = f"{self.base_url}{endpoint}"
        
        try:
            if method.upper() == 'GET':
                response = self.session.get(url)
            elif method.upper() == 'POST':
                response = self.session.post(url, json=data)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„HTTPæ–¹æ³•: {method}")
            
            response.raise_for_status()
            return True, response.json()
            
        except requests.exceptions.RequestException as e:
            logger.error(f"è¯·æ±‚å¤±è´¥ {url}: {str(e)}")
            return False, {'error': str(e)}
        except json.JSONDecodeError as e:
            logger.error(f"JSONè§£æå¤±è´¥ {url}: {str(e)}")
            return False, {'error': f'JSONè§£æå¤±è´¥: {str(e)}'}

    def check_system_status(self) -> Dict:
        """æ£€æŸ¥ç³»ç»ŸçŠ¶æ€"""
        logger.info("ğŸ” æ£€æŸ¥ç³»ç»ŸçŠ¶æ€...")
        
        status_checks = {
            'api_connection': {'endpoint': '/api/connection/status', 'required': True},
            'system_status': {'endpoint': '/api/status', 'required': True},
            'data_sources_status': {'endpoint': '/api/data_sources/status', 'required': False}
        }
        
        results = {}
        
        for check_name, check_config in status_checks.items():
            success, response = self.make_request(check_config['endpoint'])
            
            results[check_name] = {
                'success': success,
                'response': response,
                'critical': check_config['required'],
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
            if success:
                logger.info(f"âœ… {check_name}: æ­£å¸¸")
            else:
                level = logger.error if check_config['required'] else logger.warning
                level(f"âŒ {check_name}: å¤±è´¥ - {response.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        return results

    def test_single_stock_all_sources(self, stock_code: str) -> Dict:
        """æµ‹è¯•å•åªè‚¡ç¥¨çš„æ‰€æœ‰æ•°æ®æº"""
        logger.info(f"ğŸ“Š æµ‹è¯•è‚¡ç¥¨ {stock_code} çš„æ‰€æœ‰æ•°æ®æº...")
        
        # è°ƒç”¨APIæµ‹è¯•æ‰€æœ‰æ•°æ®æº
        success, response = self.make_request(f'/api/realtime/test/{stock_code}')
        
        if not success:
            logger.error(f"âŒ æ— æ³•è·å– {stock_code} çš„æµ‹è¯•ç»“æœ")
            return {
                'stock_code': stock_code,
                'success': False,
                'error': response.get('error', 'æœªçŸ¥é”™è¯¯'),
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
        
        # å¤„ç†æµ‹è¯•ç»“æœ
        test_result = {
            'stock_code': stock_code,
            'success': True,
            'test_time': response.get('timestamp', datetime.now().strftime('%Y-%m-%d %H:%M:%S')),
            'sources': {},
            'data_quality_summary': {}
        }
        
        # åˆ†ææ¯ä¸ªæ•°æ®æºçš„ç»“æœ
        source_results = response.get('results', {})
        
        for source_name, source_data in source_results.items():
            # æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
            integrity_score = self._check_data_integrity(source_data.get('data', {}))
            
            # æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥
            consistency_score = self._check_data_consistency(source_data.get('data', {}))
            
            # ç»¼åˆè¯„åˆ†
            overall_score = self._calculate_overall_score(source_data, integrity_score, consistency_score)
            
            test_result['sources'][source_name] = {
                'success': source_data.get('success', False),
                'response_time_ms': source_data.get('response_time_ms', 0),
                'error_count': source_data.get('error_count', 0),
                'is_healthy': source_data.get('is_healthy', False),
                'data': source_data.get('data', {}),
                'error': source_data.get('error', ''),
                'integrity_score': integrity_score,
                'consistency_score': consistency_score,
                'overall_score': overall_score
            }
        
        # ç”Ÿæˆæ•°æ®è´¨é‡æ±‡æ€»
        test_result['data_quality_summary'] = self._generate_quality_summary(test_result['sources'])
        
        return test_result

    def _check_data_integrity(self, data: Dict) -> Dict:
        """æ£€æŸ¥æ•°æ®å®Œæ•´æ€§"""
        if not data:
            return {
                'score': 0,
                'details': {'error': 'æ— æ•°æ®'},
                'issues': ['æ— æ•°æ®']
            }
        
        score = 0
        max_score = 100
        issues = []
        details = {}
        
        # 1. å¿…éœ€å­—æ®µæ£€æŸ¥ (40åˆ†)
        required_fields = self.data_integrity_rules['required_fields']
        field_score = 0
        missing_fields = []
        
        for field in required_fields:
            if field in data and data[field] is not None:
                try:
                    value = float(data[field])
                    if value >= 0:  # ä»·æ ¼ã€æˆäº¤é‡ç­‰åº”è¯¥éè´Ÿ
                        field_score += 40 / len(required_fields)
                    else:
                        issues.append(f"{field}å€¼ä¸ºè´Ÿæ•°: {value}")
                except (ValueError, TypeError):
                    issues.append(f"{field}ä¸æ˜¯æœ‰æ•ˆæ•°å€¼: {data[field]}")
            else:
                missing_fields.append(field)
        
        if missing_fields:
            issues.append(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {missing_fields}")
        
        details['required_fields_score'] = field_score
        score += field_score
        
        # 2. ä»·æ ¼é€»è¾‘æ£€æŸ¥ (30åˆ†)
        price_logic_score = 0
        try:
            last_price = float(data.get('lastPrice', 0))
            high = float(data.get('high', 0))
            low = float(data.get('low', 0))
            open_price = float(data.get('open', 0))
            
            if last_price > 0 and high > 0 and low > 0:
                if low <= last_price <= high:
                    price_logic_score += 15
                else:
                    issues.append(f"ä»·æ ¼é€»è¾‘é”™è¯¯: low({low}) <= lastPrice({last_price}) <= high({high})")
                
                if low <= open_price <= high:
                    price_logic_score += 15
                else:
                    issues.append(f"å¼€ç›˜ä»·é€»è¾‘é”™è¯¯: low({low}) <= open({open_price}) <= high({high})")
        except (ValueError, TypeError) as e:
            issues.append(f"ä»·æ ¼æ•°æ®ç±»å‹é”™è¯¯: {str(e)}")
        
        details['price_logic_score'] = price_logic_score
        score += price_logic_score
        
        # 3. æˆäº¤é‡æ£€æŸ¥ (15åˆ†)
        volume_score = 0
        try:
            volume = float(data.get('volume', 0))
            amount = float(data.get('amount', 0))
            
            if volume >= 0:
                volume_score += 7.5
            else:
                issues.append(f"æˆäº¤é‡ä¸ºè´Ÿ: {volume}")
            
            if amount >= 0:
                volume_score += 7.5
            else:
                issues.append(f"æˆäº¤é¢ä¸ºè´Ÿ: {amount}")
        except (ValueError, TypeError) as e:
            issues.append(f"æˆäº¤é‡æ•°æ®ç±»å‹é”™è¯¯: {str(e)}")
        
        details['volume_score'] = volume_score
        score += volume_score
        
        # 4. æ—¶é—´æˆ³æ£€æŸ¥ (15åˆ†)
        timestamp_score = 0
        if 'timestamp' in data and data['timestamp']:
            try:
                # æ£€æŸ¥æ—¶é—´æˆ³æ ¼å¼
                if isinstance(data['timestamp'], str):
                    datetime.strptime(data['timestamp'], '%Y-%m-%d %H:%M:%S')
                    timestamp_score = 15
                elif isinstance(data['timestamp'], (int, float)):
                    # Unixæ—¶é—´æˆ³
                    timestamp_score = 15
            except ValueError:
                issues.append(f"æ—¶é—´æˆ³æ ¼å¼é”™è¯¯: {data['timestamp']}")
        else:
            issues.append("ç¼ºå°‘æ—¶é—´æˆ³")
        
        details['timestamp_score'] = timestamp_score
        score += timestamp_score
        
        return {
            'score': min(score, max_score),
            'details': details,
            'issues': issues
        }

    def _check_data_consistency(self, data: Dict) -> Dict:
        """æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§"""
        if not data:
            return {
                'score': 0,
                'details': {'error': 'æ— æ•°æ®'},
                'issues': ['æ— æ•°æ®']
            }
        
        score = 0
        max_score = 100
        issues = []
        details = {}
        
        try:
            # 1. ä»·æ ¼å˜åŒ–åˆç†æ€§ (40åˆ†)
            last_price = float(data.get('lastPrice', 0))
            last_close = float(data.get('lastClose', 0))
            change = data.get('change', 0)
            change_percent = data.get('changePercent', 0)
            
            if last_close > 0 and last_price > 0:
                # è®¡ç®—ç†è®ºæ¶¨è·Œé¢å’Œæ¶¨è·Œå¹…
                expected_change = last_price - last_close
                expected_change_percent = (expected_change / last_close) * 100
                
                # æ£€æŸ¥æ¶¨è·Œé¢ä¸€è‡´æ€§
                if change is not None:
                    change_diff = abs(float(change) - expected_change)
                    if change_diff < 0.01:  # å®¹å¿0.01çš„è¯¯å·®
                        score += 20
                    else:
                        issues.append(f"æ¶¨è·Œé¢ä¸ä¸€è‡´: ç»™å®š{change}, è®¡ç®—{expected_change:.2f}")
                
                # æ£€æŸ¥æ¶¨è·Œå¹…ä¸€è‡´æ€§
                if change_percent is not None:
                    percent_diff = abs(float(change_percent) - expected_change_percent)
                    if percent_diff < 0.01:  # å®¹å¿0.01%çš„è¯¯å·®
                        score += 20
                    else:
                        issues.append(f"æ¶¨è·Œå¹…ä¸ä¸€è‡´: ç»™å®š{change_percent}%, è®¡ç®—{expected_change_percent:.2f}%")
            
            # 2. ä¹°å–ä»·æ ¼åˆç†æ€§ (30åˆ†)
            bid_prices = data.get('bidPrice', [])
            ask_prices = data.get('askPrice', [])
            
            if bid_prices and ask_prices:
                try:
                    max_bid = max([float(p) for p in bid_prices if p > 0])
                    min_ask = min([float(p) for p in ask_prices if p > 0])
                    
                    if max_bid <= min_ask:
                        score += 15
                    else:
                        issues.append(f"ä¹°å–ä»·æ ¼å€’æŒ‚: æœ€é«˜ä¹°ä»·{max_bid} > æœ€ä½å–ä»·{min_ask}")
                    
                    # æ£€æŸ¥ä»·æ ¼æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…
                    if last_price > 0:
                        if max_bid <= last_price <= min_ask or abs(last_price - max_bid) / last_price < 0.1:
                            score += 15
                        else:
                            issues.append(f"æœ€æ–°ä»·æ ¼åç¦»ä¹°å–ä»·è¿‡è¿œ: lastPrice={last_price}, bid={max_bid}, ask={min_ask}")
                except (ValueError, TypeError) as e:
                    issues.append(f"ä¹°å–ä»·æ ¼æ•°æ®é”™è¯¯: {str(e)}")
            
            # 3. æˆäº¤é‡ä¸æˆäº¤é¢ä¸€è‡´æ€§ (30åˆ†)
            volume = float(data.get('volume', 0))
            amount = float(data.get('amount', 0))
            
            if volume > 0 and amount > 0 and last_price > 0:
                # ä¼°ç®—å¹³å‡æˆäº¤ä»·
                avg_price = amount / volume
                price_deviation = abs(avg_price - last_price) / last_price
                
                if price_deviation < 0.1:  # 10%ä»¥å†…çš„åå·®è®¤ä¸ºåˆç†
                    score += 30
                else:
                    issues.append(f"æˆäº¤å‡ä»·åç¦»è¿‡å¤§: å‡ä»·{avg_price:.2f}, æœ€æ–°ä»·{last_price:.2f}")
            
        except (ValueError, TypeError, ZeroDivisionError) as e:
            issues.append(f"æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥é”™è¯¯: {str(e)}")
        
        details['final_score'] = score
        
        return {
            'score': min(score, max_score),
            'details': details,
            'issues': issues
        }

    def _calculate_overall_score(self, source_data: Dict, integrity_result: Dict, consistency_result: Dict) -> Dict:
        """è®¡ç®—ç»¼åˆè¯„åˆ†"""
        # æƒé‡è®¾ç½®
        weights = {
            'success': 0.3,       # æ¥å£æˆåŠŸç‡
            'performance': 0.2,   # å“åº”æ€§èƒ½
            'integrity': 0.3,     # æ•°æ®å®Œæ•´æ€§
            'consistency': 0.2    # æ•°æ®ä¸€è‡´æ€§
        }
        
        # æˆåŠŸç‡è¯„åˆ†
        success_score = 100 if source_data.get('success', False) else 0
        
        # æ€§èƒ½è¯„åˆ† (å“åº”æ—¶é—´)
        response_time = source_data.get('response_time_ms', 999999)
        if response_time < 100:
            performance_score = 100
        elif response_time < 500:
            performance_score = 90
        elif response_time < 1000:
            performance_score = 80
        elif response_time < 2000:
            performance_score = 60
        elif response_time < 5000:
            performance_score = 40
        else:
            performance_score = 20
        
        # å®Œæ•´æ€§å’Œä¸€è‡´æ€§è¯„åˆ†
        integrity_score = integrity_result.get('score', 0)
        consistency_score = consistency_result.get('score', 0)
        
        # è®¡ç®—åŠ æƒæ€»åˆ†
        overall_score = (
            success_score * weights['success'] +
            performance_score * weights['performance'] +
            integrity_score * weights['integrity'] +
            consistency_score * weights['consistency']
        )
        
        # ç­‰çº§è¯„å®š
        if overall_score >= 90:
            grade = 'A'
            description = 'ä¼˜ç§€'
        elif overall_score >= 80:
            grade = 'B'
            description = 'è‰¯å¥½'
        elif overall_score >= 70:
            grade = 'C'
            description = 'ä¸€èˆ¬'
        elif overall_score >= 60:
            grade = 'D'
            description = 'è¾ƒå·®'
        else:
            grade = 'F'
            description = 'å¤±è´¥'
        
        return {
            'overall_score': round(overall_score, 2),
            'grade': grade,
            'description': description,
            'component_scores': {
                'success': success_score,
                'performance': performance_score,
                'integrity': integrity_score,
                'consistency': consistency_score
            },
            'weights': weights
        }

    def _generate_quality_summary(self, sources_results: Dict) -> Dict:
        """ç”Ÿæˆæ•°æ®è´¨é‡æ±‡æ€»"""
        summary = {
            'total_sources': len(sources_results),
            'successful_sources': 0,
            'average_response_time': 0,
            'best_source': None,
            'worst_source': None,
            'source_rankings': []
        }
        
        if not sources_results:
            return summary
        
        response_times = []
        source_scores = []
        
        for source_name, result in sources_results.items():
            if result.get('success', False):
                summary['successful_sources'] += 1
                response_times.append(result.get('response_time_ms', 0))
            
            overall_score = result.get('overall_score', {}).get('overall_score', 0)
            source_scores.append({
                'source': source_name,
                'score': overall_score,
                'grade': result.get('overall_score', {}).get('grade', 'F')
            })
        
        # è®¡ç®—å¹³å‡å“åº”æ—¶é—´
        if response_times:
            summary['average_response_time'] = round(statistics.mean(response_times), 2)
        
        # æ’åºå¹¶æ‰¾å‡ºæœ€ä½³å’Œæœ€å·®æ•°æ®æº
        source_scores.sort(key=lambda x: x['score'], reverse=True)
        summary['source_rankings'] = source_scores
        
        if source_scores:
            summary['best_source'] = source_scores[0]
            summary['worst_source'] = source_scores[-1]
        
        return summary

    def test_data_source_switching(self) -> Dict:
        """æµ‹è¯•æ•°æ®æºåˆ‡æ¢åŠŸèƒ½"""
        logger.info("ğŸ”„ æµ‹è¯•æ•°æ®æºåˆ‡æ¢åŠŸèƒ½...")
        
        # è·å–å½“å‰æ•°æ®æºçŠ¶æ€
        success, status_response = self.make_request('/api/data_sources/status')
        if not success:
            return {
                'success': False,
                'error': 'æ— æ³•è·å–æ•°æ®æºçŠ¶æ€',
                'details': status_response
            }
        
        switch_results = {
            'success': True,
            'original_status': status_response,
            'switch_tests': [],
            'restoration_success': False
        }
        
        # è·å–å¯ç”¨çš„æ•°æ®æºåˆ—è¡¨
        available_sources = []
        current_source = None
        
        if 'data' in status_response:
            for source_name, source_info in status_response['data'].items():
                available_sources.append(source_name)
                if source_info.get('is_current', False):
                    current_source = source_name
        
        # æµ‹è¯•åˆ‡æ¢åˆ°æ¯ä¸ªæ•°æ®æº
        for source_name in available_sources:
            if source_name == current_source:
                continue  # è·³è¿‡å½“å‰æ•°æ®æº
            
            logger.info(f"åˆ‡æ¢åˆ°æ•°æ®æº: {source_name}")
            
            switch_success, switch_response = self.make_request(
                '/api/data_sources/switch',
                'POST',
                {'source_name': source_name}
            )
            
            switch_test = {
                'target_source': source_name,
                'switch_success': switch_success,
                'switch_response': switch_response,
                'verification_success': False,
                'test_data_quality': {}
            }
            
            if switch_success:
                # éªŒè¯åˆ‡æ¢æ˜¯å¦æˆåŠŸ
                time.sleep(1)  # ç­‰å¾…åˆ‡æ¢ç”Ÿæ•ˆ
                
                # æµ‹è¯•æ•°æ®è·å–
                test_stock = self.test_stocks[0]
                quote_success, quote_response = self.make_request(f'/api/realtime/quote/{test_stock}')
                
                if quote_success and quote_response.get('status') == 'success':
                    switch_test['verification_success'] = True
                    switch_test['test_data_quality'] = self._check_data_integrity(
                        quote_response.get('data', {})
                    )
                else:
                    switch_test['verification_error'] = quote_response.get('message', 'æ•°æ®è·å–å¤±è´¥')
            
            switch_results['switch_tests'].append(switch_test)
        
        # æ¢å¤åˆ°åŸå§‹æ•°æ®æº
        if current_source:
            restore_success, restore_response = self.make_request(
                '/api/data_sources/switch',
                'POST',
                {'source_name': current_source}
            )
            switch_results['restoration_success'] = restore_success
            switch_results['restore_response'] = restore_response
        
        return switch_results

    def run_comprehensive_test(self) -> Dict:
        """è¿è¡Œç»¼åˆæµ‹è¯•"""
        logger.info("=" * 80)
        logger.info("ğŸš€ å¼€å§‹Web APIå®æ—¶æ•°æ®æºå®Œæ•´æ€§æµ‹è¯•")
        logger.info("=" * 80)
        
        test_start_time = datetime.now()
        
        comprehensive_results = {
            'test_info': {
                'start_time': test_start_time.strftime('%Y-%m-%d %H:%M:%S'),
                'base_url': self.base_url,
                'test_stocks': self.test_stocks,
                'test_type': 'Web API Integration Test'
            },
            'system_status': {},
            'stock_tests': {},
            'switch_test': {},
            'summary': {},
            'recommendations': []
        }
        
        # 1. ç³»ç»ŸçŠ¶æ€æ£€æŸ¥
        comprehensive_results['system_status'] = self.check_system_status()
        
        # æ£€æŸ¥å…³é”®ç³»ç»Ÿæ˜¯å¦å¯ç”¨
        critical_failures = [
            check for check, result in comprehensive_results['system_status'].items()
            if result['critical'] and not result['success']
        ]
        
        if critical_failures:
            logger.error(f"âŒ å…³é”®ç³»ç»Ÿæ£€æŸ¥å¤±è´¥: {critical_failures}")
            comprehensive_results['summary'] = {
                'overall_success': False,
                'critical_failures': critical_failures,
                'message': 'ç³»ç»ŸçŠ¶æ€æ£€æŸ¥å¤±è´¥ï¼Œæ— æ³•ç»§ç»­æµ‹è¯•'
            }
            return comprehensive_results
        
        # 2. è‚¡ç¥¨æ•°æ®æµ‹è¯•
        logger.info(f"ğŸ“ˆ å¼€å§‹æµ‹è¯• {len(self.test_stocks)} åªè‚¡ç¥¨...")
        
        # å¹¶è¡Œæµ‹è¯•å¤šåªè‚¡ç¥¨
        with ThreadPoolExecutor(max_workers=3) as executor:
            future_to_stock = {
                executor.submit(self.test_single_stock_all_sources, stock): stock 
                for stock in self.test_stocks
            }
            
            for future in as_completed(future_to_stock):
                stock_code = future_to_stock[future]
                try:
                    result = future.result()
                    comprehensive_results['stock_tests'][stock_code] = result
                except Exception as e:
                    logger.error(f"âŒ æµ‹è¯•è‚¡ç¥¨ {stock_code} æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
                    comprehensive_results['stock_tests'][stock_code] = {
                        'success': False,
                        'error': str(e)
                    }
        
        # 3. æ•°æ®æºåˆ‡æ¢æµ‹è¯•
        comprehensive_results['switch_test'] = self.test_data_source_switching()
        
        # 4. ç”Ÿæˆç»¼åˆåˆ†æ
        comprehensive_results['summary'] = self._generate_comprehensive_summary(comprehensive_results)
        
        # 5. ç”Ÿæˆæ”¹è¿›å»ºè®®
        comprehensive_results['recommendations'] = self._generate_recommendations(comprehensive_results)
        
        test_end_time = datetime.now()
        comprehensive_results['test_info']['end_time'] = test_end_time.strftime('%Y-%m-%d %H:%M:%S')
        comprehensive_results['test_info']['duration_seconds'] = (test_end_time - test_start_time).total_seconds()
        
        logger.info("âœ… ç»¼åˆæµ‹è¯•å®Œæˆï¼")
        
        return comprehensive_results

    def _generate_comprehensive_summary(self, results: Dict) -> Dict:
        """ç”Ÿæˆç»¼åˆæµ‹è¯•æ±‡æ€»"""
        summary = {
            'overall_success': True,
            'system_health': {},
            'data_source_performance': {},
            'data_quality_overview': {},
            'key_findings': []
        }
        
        # ç³»ç»Ÿå¥åº·çŠ¶å†µ
        system_checks = results.get('system_status', {})
        system_health = {
            'total_checks': len(system_checks),
            'passed_checks': sum(1 for check in system_checks.values() if check['success']),
            'critical_failures': [
                name for name, check in system_checks.items()
                if check['critical'] and not check['success']
            ]
        }
        system_health['health_score'] = (system_health['passed_checks'] / system_health['total_checks']) * 100 if system_health['total_checks'] > 0 else 0
        summary['system_health'] = system_health
        
        # æ•°æ®æºæ€§èƒ½ç»Ÿè®¡
        source_stats = {}
        all_sources = set()
        
        for stock_code, stock_result in results.get('stock_tests', {}).items():
            if not stock_result.get('success', False):
                continue
                
            for source_name, source_result in stock_result.get('sources', {}).items():
                all_sources.add(source_name)
                
                if source_name not in source_stats:
                    source_stats[source_name] = {
                        'total_tests': 0,
                        'successful_tests': 0,
                        'response_times': [],
                        'integrity_scores': [],
                        'consistency_scores': [],
                        'overall_scores': []
                    }
                
                stats = source_stats[source_name]
                stats['total_tests'] += 1
                
                if source_result.get('success', False):
                    stats['successful_tests'] += 1
                    stats['response_times'].append(source_result.get('response_time_ms', 0))
                    stats['integrity_scores'].append(source_result.get('integrity_score', {}).get('score', 0))
                    stats['consistency_scores'].append(source_result.get('consistency_score', {}).get('score', 0))
                    stats['overall_scores'].append(source_result.get('overall_score', {}).get('overall_score', 0))
        
        # è®¡ç®—å„æ•°æ®æºçš„ç»¼åˆæŒ‡æ ‡
        performance_summary = {}
        for source_name, stats in source_stats.items():
            perf = {
                'success_rate': (stats['successful_tests'] / stats['total_tests']) * 100 if stats['total_tests'] > 0 else 0,
                'avg_response_time': statistics.mean(stats['response_times']) if stats['response_times'] else 0,
                'avg_integrity_score': statistics.mean(stats['integrity_scores']) if stats['integrity_scores'] else 0,
                'avg_consistency_score': statistics.mean(stats['consistency_scores']) if stats['consistency_scores'] else 0,
                'avg_overall_score': statistics.mean(stats['overall_scores']) if stats['overall_scores'] else 0
            }
            performance_summary[source_name] = perf
        
        summary['data_source_performance'] = performance_summary
        
        # æ•°æ®è´¨é‡æ¦‚è§ˆ
        quality_overview = {
            'total_stock_tests': len(results.get('stock_tests', {})),
            'successful_stock_tests': sum(1 for test in results.get('stock_tests', {}).values() if test.get('success', False)),
            'average_data_quality': 0,
            'quality_distribution': {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'F': 0}
        }
        
        all_quality_scores = []
        for stock_result in results.get('stock_tests', {}).values():
            if not stock_result.get('success', False):
                continue
            for source_result in stock_result.get('sources', {}).values():
                if source_result.get('success', False):
                    score = source_result.get('overall_score', {}).get('overall_score', 0)
                    grade = source_result.get('overall_score', {}).get('grade', 'F')
                    all_quality_scores.append(score)
                    quality_overview['quality_distribution'][grade] += 1
        
        if all_quality_scores:
            quality_overview['average_data_quality'] = statistics.mean(all_quality_scores)
        
        summary['data_quality_overview'] = quality_overview
        
        # å…³é”®å‘ç°
        findings = []
        
        # æ‰¾å‡ºæœ€ä½³å’Œæœ€å·®æ•°æ®æº
        if performance_summary:
            best_source = max(performance_summary.items(), key=lambda x: x[1]['avg_overall_score'])
            worst_source = min(performance_summary.items(), key=lambda x: x[1]['avg_overall_score'])
            
            findings.append(f"æœ€ä½³æ•°æ®æº: {best_source[0]} (ç»¼åˆå¾—åˆ†: {best_source[1]['avg_overall_score']:.1f})")
            findings.append(f"æœ€å·®æ•°æ®æº: {worst_source[0]} (ç»¼åˆå¾—åˆ†: {worst_source[1]['avg_overall_score']:.1f})")
        
        # æ€§èƒ½è­¦å‘Š
        for source_name, perf in performance_summary.items():
            if perf['success_rate'] < 80:
                findings.append(f"âš ï¸ {source_name} æˆåŠŸç‡åä½: {perf['success_rate']:.1f}%")
            if perf['avg_response_time'] > 2000:
                findings.append(f"âš ï¸ {source_name} å“åº”æ—¶é—´è¾ƒæ…¢: {perf['avg_response_time']:.1f}ms")
        
        summary['key_findings'] = findings
        
        # åˆ¤æ–­æ€»ä½“æˆåŠŸ
        if system_health['critical_failures'] or quality_overview['average_data_quality'] < 60:
            summary['overall_success'] = False
        
        return summary

    def _generate_recommendations(self, results: Dict) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        summary = results.get('summary', {})
        performance = summary.get('data_source_performance', {})
        
        # åŸºäºæ€§èƒ½æ•°æ®ç”Ÿæˆå»ºè®®
        for source_name, perf in performance.items():
            if perf['success_rate'] < 50:
                recommendations.append(f"ğŸ”§ å»ºè®®æ£€æŸ¥ {source_name} æ•°æ®æºé…ç½®ï¼ŒæˆåŠŸç‡è¿‡ä½ ({perf['success_rate']:.1f}%)")
            
            if perf['avg_response_time'] > 5000:
                recommendations.append(f"âš¡ å»ºè®®ä¼˜åŒ– {source_name} ç½‘ç»œè¿æ¥ï¼Œå“åº”æ—¶é—´è¿‡æ…¢ ({perf['avg_response_time']:.1f}ms)")
            
            if perf['avg_integrity_score'] < 70:
                recommendations.append(f"ğŸ“Š å»ºè®®ä¿®å¤ {source_name} æ•°æ®å®Œæ•´æ€§é—®é¢˜ï¼Œå®Œæ•´æ€§å¾—åˆ†è¿‡ä½ ({perf['avg_integrity_score']:.1f})")
        
        # ç³»ç»Ÿçº§å»ºè®®
        switch_test = results.get('switch_test', {})
        if not switch_test.get('success', True):
            recommendations.append("ğŸ”„ å»ºè®®æ£€æŸ¥æ•°æ®æºåˆ‡æ¢åŠŸèƒ½ï¼Œåˆ‡æ¢æµ‹è¯•å¤±è´¥")
        
        # æ•°æ®è´¨é‡å»ºè®®
        quality = summary.get('data_quality_overview', {})
        if quality.get('average_data_quality', 0) < 80:
            recommendations.append("ğŸ“ˆ å»ºè®®æå‡æ•´ä½“æ•°æ®è´¨é‡ï¼Œå½“å‰å¹³å‡è´¨é‡å¾—åˆ†åä½")
        
        # å¦‚æœæ²¡æœ‰å‘ç°é—®é¢˜ï¼Œç»™å‡ºä¼˜åŒ–å»ºè®®
        if not recommendations:
            recommendations.append("âœ… ç³»ç»Ÿæ•´ä½“è¿è¡Œè‰¯å¥½ï¼Œå»ºè®®å®šæœŸç›‘æ§æ•°æ®è´¨é‡")
            recommendations.append("ğŸ“Š å»ºè®®å¢åŠ æ›´å¤šè‚¡ç¥¨æ ·æœ¬è¿›è¡Œæµ‹è¯•")
            recommendations.append("â° å»ºè®®è®¾ç½®è‡ªåŠ¨åŒ–å®šæ—¶æµ‹è¯•")
        
        return recommendations

    def print_detailed_report(self, results: Dict):
        """æ‰“å°è¯¦ç»†æµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "=" * 100)
        print("ğŸ“‹ WEB API å®æ—¶æ•°æ®æºå®Œæ•´æ€§æµ‹è¯•æŠ¥å‘Š")
        print("=" * 100)
        
        # åŸºæœ¬ä¿¡æ¯
        test_info = results.get('test_info', {})
        print(f"ğŸ• æµ‹è¯•æ—¶é—´: {test_info.get('start_time')} - {test_info.get('end_time')}")
        print(f"â±ï¸ æµ‹è¯•è€—æ—¶: {test_info.get('duration_seconds', 0):.2f} ç§’")
        print(f"ğŸŒ æµ‹è¯•URL: {test_info.get('base_url')}")
        print(f"ğŸ“ˆ æµ‹è¯•è‚¡ç¥¨: {len(test_info.get('test_stocks', []))} åª")
        
        # ç³»ç»Ÿå¥åº·çŠ¶å†µ
        print(f"\nğŸ¥ ç³»ç»Ÿå¥åº·çŠ¶å†µ:")
        system_health = results.get('summary', {}).get('system_health', {})
        health_score = system_health.get('health_score', 0)
        print(f"   å¥åº·å¾—åˆ†: {health_score:.1f}% ({system_health.get('passed_checks', 0)}/{system_health.get('total_checks', 0)} æ£€æŸ¥é€šè¿‡)")
        
        if system_health.get('critical_failures'):
            print(f"   âŒ å…³é”®å¤±è´¥: {', '.join(system_health['critical_failures'])}")
        else:
            print(f"   âœ… æ‰€æœ‰å…³é”®æ£€æŸ¥é€šè¿‡")
        
        # æ•°æ®æºæ€§èƒ½å¯¹æ¯”
        print(f"\nğŸ“Š æ•°æ®æºæ€§èƒ½å¯¹æ¯”:")
        performance = results.get('summary', {}).get('data_source_performance', {})
        
        if performance:
            print(f"{'æ•°æ®æº':<15} {'æˆåŠŸç‡':<8} {'å“åº”æ—¶é—´':<10} {'å®Œæ•´æ€§':<8} {'ä¸€è‡´æ€§':<8} {'ç»¼åˆå¾—åˆ†':<8} {'ç­‰çº§'}")
            print("-" * 85)
            
            for source_name, perf in performance.items():
                print(f"{source_name:<15} "
                      f"{perf['success_rate']:<7.1f}% "
                      f"{perf['avg_response_time']:<9.0f}ms "
                      f"{perf['avg_integrity_score']:<7.1f} "
                      f"{perf['avg_consistency_score']:<7.1f} "
                      f"{perf['avg_overall_score']:<7.1f} "
                      f"{'A' if perf['avg_overall_score'] >= 90 else 'B' if perf['avg_overall_score'] >= 80 else 'C' if perf['avg_overall_score'] >= 70 else 'D' if perf['avg_overall_score'] >= 60 else 'F'}")
        
        # æ•°æ®è´¨é‡åˆ†å¸ƒ
        print(f"\nğŸ“ˆ æ•°æ®è´¨é‡åˆ†å¸ƒ:")
        quality = results.get('summary', {}).get('data_quality_overview', {})
        dist = quality.get('quality_distribution', {})
        total_tests = sum(dist.values())
        
        if total_tests > 0:
            for grade in ['A', 'B', 'C', 'D', 'F']:
                count = dist.get(grade, 0)
                percentage = (count / total_tests) * 100
                bar = "â–ˆ" * int(percentage / 2)
                print(f"   {grade}çº§: {count:>3} ({percentage:>5.1f}%) {bar}")
        
        print(f"   å¹³å‡è´¨é‡å¾—åˆ†: {quality.get('average_data_quality', 0):.1f}")
        
        # å…³é”®å‘ç°
        print(f"\nğŸ” å…³é”®å‘ç°:")
        findings = results.get('summary', {}).get('key_findings', [])
        for finding in findings:
            print(f"   â€¢ {finding}")
        
        # æ”¹è¿›å»ºè®®
        print(f"\nğŸ’¡ æ”¹è¿›å»ºè®®:")
        recommendations = results.get('recommendations', [])
        for rec in recommendations:
            print(f"   â€¢ {rec}")
        
        # æ€»ä½“ç»“è®º
        overall_success = results.get('summary', {}).get('overall_success', False)
        print(f"\nğŸ¯ æ€»ä½“ç»“è®º: {'âœ… æµ‹è¯•é€šè¿‡' if overall_success else 'âŒ éœ€è¦æ”¹è¿›'}")

    def save_results(self, results: Dict, filename: str = None):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        if filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"web_api_data_source_test_results_{timestamp}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ“ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {filename}")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {str(e)}")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Web API å®æ—¶æ•°æ®æºå®Œæ•´æ€§æµ‹è¯•')
    parser.add_argument('--url', default='http://127.0.0.1:5000', help='APIæœåŠ¡å™¨åœ°å€')
    parser.add_argument('--stocks', nargs='+', help='æŒ‡å®šæµ‹è¯•è‚¡ç¥¨ä»£ç ')
    parser.add_argument('--output', help='ç»“æœè¾“å‡ºæ–‡ä»¶å')
    
    args = parser.parse_args()
    
    print("ğŸš€ å¯åŠ¨Web APIå®æ—¶æ•°æ®æºå®Œæ•´æ€§æµ‹è¯•...")
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = WebAPIDataSourceTester(base_url=args.url)
    
    # å¦‚æœæŒ‡å®šäº†è‚¡ç¥¨ä»£ç ï¼Œä½¿ç”¨æŒ‡å®šçš„
    if args.stocks:
        tester.test_stocks = args.stocks
    
    # è¿è¡Œæµ‹è¯•
    try:
        results = tester.run_comprehensive_test()
        
        # æ˜¾ç¤ºæŠ¥å‘Š
        tester.print_detailed_report(results)
        
        # ä¿å­˜ç»“æœ
        tester.save_results(results, args.output)
        
        print("\nâœ… æµ‹è¯•å®Œæˆï¼")
        
        # æ ¹æ®æµ‹è¯•ç»“æœè¿”å›é€‚å½“çš„é€€å‡ºç 
        overall_success = results.get('summary', {}).get('overall_success', False)
        exit(0 if overall_success else 1)
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        exit(1)
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        exit(1)


if __name__ == "__main__":
    main()